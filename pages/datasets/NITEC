---
title: SEMIAC
description: "Implicit mobile human-robot communication for spatial action coordination with action-specific semantic environment modelling"
background: /assets/theme/images/home.png
permalink: /datasets/NITEC/
---

{: .alert .alert-warning}
 
![image](https://github.com/thohemp/archive/blob/main/nitec.gif)

<!-- # SEMIAC -->


## NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction
Eye contact is a crucial non-verbal interaction modality and plays an important role in our everyday social life. While humans are very sensitive to eye contact, the capabilities of machines to capture a person's gaze are still mediocre. We tackle this challenge and present NITEC, a hand-annotated eye contact dataset for ego-vision interaction. NITEC exceeds existing datasets for ego-vision eye contact in size and variety of demographics, social contexts, and lighting conditions, making it a valuable resource for advancing ego-vision-based eye contact research. Our extensive evaluations on NITEC demonstrate strong cross-dataset performance, emphasizing its effectiveness and adaptability in various scenarios, that allows seamless utilization to the fields of computer vision, human-computer interaction, and social robotics. We make our NITEC dataset publicly available to foster reproducibility and further exploration in the field of ego-vision interaction.

### Quick Usage Information
- Repository: [NITEC](https://github.com/thohemp/nitec)

# Founding
The project is funded by the German Research Foundation (DFG) under grant No. 502483052 and is planned with a project duration of 3 years (2023 to 2026).


